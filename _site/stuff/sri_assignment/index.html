<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- jQuery -->
  <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
    integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
    integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
    crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
    integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
    crossorigin="anonymous"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">

  <!-- favicon -->
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon_io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon_io/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon_io/favicon-16x16.png">
  <link rel="manifest" href="/assets/favicon_io/site.webmanifest">

<!-- Scripts mainly for the publication part -->
<script src="https://code.iconify.design/1/1.0.6/iconify.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js/src/bibtex_js.js"></script>
<script type="text/javascript">
  function reset() {
      $("select").each(function () {
	  localStorage.setItem($(this).attr("id"),"");
	  $(this).val("");
      });
      $("#searchbar").val("");
      $("#searchbar").trigger('change');
  }
</script>

<!-- Remember to include jQuery :) -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.0.0/jquery.min.js"></script>

<!-- Academics -->
<link rel="stylesheet"
href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

<!-- jQuery Modal -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-modal/0.9.1/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery-modal/0.9.1/jquery.modal.min.css" />

<!-- additional CSS information -->
<style>
  /* Bibtex navigation bar */
  .bibtex_search_bar {
      text-align: center;
  }

  /* Bibtex item */
  .bibtexentry {
      margin-top: 0.2em;
      margin-bottom: 02em;
  }

  .url {
      background: url('https://api.iconify.design/il:url.svg') no-repeat center center / contain;
  }

  .modal { max-width: 90%; }

  /* The alert message box */
  .alert {
      padding: 20px;
      background-color: #f44336; /* Red */
      color: white;
      margin-bottom: 15px;
      width: 50%;
      margin-left: auto;
      margin-right: auto;
  }

</style>


</head>


  <body>

    <div class="container-fluid">
      <div><header class="site-header" role="banner">

	<nav class="navbar navbar-expand-sm navbar-light px-0">

		<!-- Navbar brand -->
		<a class="navbar-brand" href="/">MADHAV Lab</a>

		<!-- Navbar toggler button -->
		<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarToggler"
			aria-controls="navbarToggler" aria-expanded="false" aria-label="Toggle navigation">
			<span class="navbar-toggler-icon"></span>
		</button>

		<!-- Navbar links -->
		<div class="collapse navbar-collapse" id="navbarToggler">
			<ul class="navbar-nav mr-auto">
				<li>
					<a class="nav-link" href="/team">Team</a>
				</li>
				<li>
					<a class="nav-link" href="/publications">Publications</a>
				</li>
				<li>
					<a class="nav-link" href="/projects">Projects</a>
				</li>
				<li>
					<a class="nav-link" href="/outcomes">Outcomes</a>
				</li>
				<li>
					<a class="nav-link" href="/jobs">Jobs</a>
				</li>
				<li>
					<a class="nav-link" href="/resources">Resources</a>
				</li>
				<li>
					<a class="nav-link" href="/gallery">Gallery</a>
				</li>
			</ul>
		</div>

	</nav>

</header>
</div>

      <div class="mt-3">
        <div>
	<h1 class="mb-5">Coding Task: Summer Research Internship</h1>
	<h3 id="guidelines">Guidelines:</h3>
<ul>
  <li>There are 4 tasks in total for different project-openings.</li>
  <li>You are required to solve and submit at least 1 of these 4 tasks of your choice, before the deadline.</li>
  <li>Each participant can solve and submit as many tasks.</li>
  <li>The submission deadline is strict and no exceptions will be made for extensions.</li>
  <li>You can submit a Google Colab/ Jupyter notebook (.ipynb) or a zip of .py files.</li>
  <li>Ensure that all links in the submitted form are accessible (not private).</li>
  <li>The deadline to submit is <strong>1:00 PM (IST) 6th February (Tuesday), 2024</strong>.</li>
  <li>Submission link- <a href="https://forms.office.com/r/QRsi0ju9pY">https://forms.office.com/r/QRsi0ju9pY</a></li>
</ul>

<h3 id="task-1-prepare-a-custom-pipeline-for-data-preparation-and-cnn-training">Task 1: Prepare a custom pipeline for data preparation and CNN training</h3>

<ol>
  <li>Use the TinySOL dataset: <a href="https://zenodo.org/records/3685367">https://zenodo.org/records/3685367</a>. You can download this by using the following commands-
    <div class="language-console highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gp"> user:~$</span><span class="w"> </span>wget https://zenodo.org/records/3685367/files/TinySOL.tar.gz
<span class="gp"> user:~$</span><span class="w"> </span>wget https://zenodo.org/records/3685367/files/TinySOL_metadata.csv
<span class="gp"> user:~$</span><span class="w"> </span>unzip TinySOL.tar.gz <span class="o">&amp;&amp;</span> <span class="nb">rm </span>TinySOL.tar.gz
</code></pre></div>    </div>
  </li>
  <li>Train a small CNN for classificying the instruments being played, given an audio file from this dataset for 30 epochs. You are free to choose all other hyperparmeters. Save this trained model.</li>
  <li>Write a general dataset class, which takes as input the path to the csv file and the folder with the audio files. When called with some input index <em>i</em>, it should return a dictionary with the following items-
    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="s">'file'</span><span class="p">:</span> <span class="n">filename</span><span class="p">,</span> <span class="c1">#name of the audio file,
</span> <span class="s">'audio'</span><span class="p">:</span> <span class="n">audio</span><span class="p">,</span> <span class="c1">#Processed ith audio of shape [1,T]
</span> <span class="s">'mel'</span><span class="p">:</span> <span class="n">mel_spectrogram</span><span class="p">,</span> <span class="c1">#Mel Spectrogram of the audio. Shape- [1,F,T]. Choose the parameters yourself.
</span> <span class="s">'gt'</span><span class="p">:</span> <span class="n">ground_truth</span><span class="p">,</span> <span class="c1">#The label mapped with the corresponding audio file.
</span> <span class="s">'pseudo'</span><span class="p">:</span> <span class="n">pseudo_label</span> <span class="c1">#Predicted label in the inference from the trained model in step-2.
</span><span class="p">}</span>
</code></pre></div>    </div>
  </li>
  <li>Now train the same CNN from scratch (untrained), but use the <em>‘psuedo_label’</em> in the dict output of the dataset as in step-3 as target variable in your loss function.</li>
  <li>Now analyze the results (accuracy, loss) and plot some graphs to contrast in the CNN’s performance when trained using the correct ground truth labels (step-2) with the case when trained using the pseudo labels.</li>
  <li><strong>BONUS</strong>: What can you do to improve the performance of the CNN in step-4 (other than increasing num_epochs in step-2)?</li>
</ol>

<h3 id="task-2-use-relevant-features-for-raga-identification">Task 2: Use relevant features for Raga Identification</h3>

<ol>
  <li>Train a simple CNN for raga identification using relevant features.</li>
  <li>Play around with different types of extracted features from the music audio files, to deduce the most relevant before finally training the model.</li>
  <li>Use the dataset available here- <a href="https://www.kaggle.com/datasets/kcwaghmarewaghmare/indian-music-raga">https://www.kaggle.com/datasets/kcwaghmarewaghmare/indian-music-raga</a>.</li>
</ol>

<h3 id="task-3-build-symbolic-equation-from-neural-network-output">Task 3: Build Symbolic Equation from Neural Network Output</h3>
<p>In this task, you will develop a program that takes the output of a 2-hidden layer feedforward neural network as input and 
constructs a symbolic equation representing the network’s output. The goal is to understand and interpret the neural network’s
decision-making process through symbolic representation.</p>

<ol>
  <li>Train a 2-hidden layer feedforward neural network with sparse connections (as in the figure below) on a dataset of your choice. Save the trained model.</li>
  <li>Extract the symbolic expression representing the output layer of the neural network. Can use <a href="https://www.sympy.org/en/index.html">SymPy</a>.</li>
  <li>Implement a Python program that takes the symbolic expression from the output layer as input. Construct a symbolic equation using the input features as variables.</li>
  <li>Allow users to input a set of values for the input features. Use the symbolic equation to compute and display the corresponding predicted output.</li>
  <li>Document the code with comments and explanations. Provide instructions on how to run the program and interpret the symbolic equation.</li>
</ol>

<div align="center">
  <p><img class="width-score" src="/stuff/sri.png" width="60%" /></p>
</div>

<h3 id="task-4-implement-papers-on-generative-modelling">Task 4: Implement paper/s on Generative Modelling</h3>
<p>In this task, you are required to implement either (or both) of the following papers from scratch-</p>

<ol>
  <li>
    <h4 id="image-inpainting-using-gan-with-contextual-attention"><a href="https://arxiv.org/pdf/1801.07892.pdf">Image Inpainting using GAN with contextual attention</a></h4>
    <p>Dataset: <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>. 
Repo: <a href="https://github.com/jiajunhua/JiahuiYu-generative_inpainting">https://github.com/jiajunhua/JiahuiYu-generative_inpainting</a></p>
  </li>
  <li>
    <h4 id="image-inpainting-using-partial-convolution"><a href="https://arxiv.org/pdf/1804.07723.pdf">Image Inpainting using Partial Convolution</a></h4>
    <p>Dataset: <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR-10</a>. 
Repo: <a href="https://github.com/Shivkumar25/Image-Inpainting">https://github.com/Shivkumar25/Image-Inpainting</a></p>
  </li>
</ol>

<hr />
<p>In case you have any queries/doubts on the problem statements, feel free to contact <a href="akshayr@iitk.ac.in">akshayr@iitk.ac.in</a>.</p>

</div>

      </div>

      <div>
        <div id="footer" class="site-footer mt-5">
	<div class="mt-3">
		<div class="row d-flex">

			<div class="col-sm-6">
				<p class="font-weight-bold">MADHAV Lab</p>

				<ul class="list-unstyled list-inline">
					<li class="list-inline-item">
						<a href="https://iitk.ac.in">
							<img class="img-fluid" src="/assets/images/iitk_logo.png" style="max-height: 80px;">
						</a>
					</li>

			</div>

			<div class="col-sm-3">
				<p class="font-weight-bold">Links</p>
				<ul class="list-unstyled">
					<li><a href="https://twitter.com/madhavlab" target="_blank">Twitter</a></li>
                    <li><a href="https://linkedin.com/company/madhav-lab" target="_blank">LinkedIn</a></li>
					<li><a href="https://github.com/madhavlab" target="_blank">Github</a></li>
				</ul>
			</div>

			<div class="col-sm-3">
				<p class="font-weight-bold">Contact</p>
				ACES 305D, <br>
				Electrical Engineering, <br>
				Indian Institue of Technology Kanpur, <br>
				UP, India <br>
			</div>
		</div>

		<div class="footer-copyright text-center py-3">
			© 2023 MADHAV Lab - Machine Analysis of Data for Human Audition and Visualization Lab
		</div>
	</div>
</div>

      </div>
    </div>

  </body>

</html>

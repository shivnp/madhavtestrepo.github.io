<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- jQuery -->
  <script src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
    integrity="sha384-J6qa4849blE2+poT4WnyKhv5vZF5SrPo0iEjwBvKU7imGFAV0wwj1yYfoRSJoZ+n"
    crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js"
    integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo"
    crossorigin="anonymous"></script>
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js"
    integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6"
    crossorigin="anonymous"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/main.css">

  <!-- favicon -->
  <link rel="apple-touch-icon" sizes="180x180" href="/assets/favicon_io/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon_io/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon_io/favicon-16x16.png">
  <link rel="manifest" href="/assets/favicon_io/site.webmanifest">

<!-- Scripts mainly for the publication part -->
<script src="https://code.iconify.design/1/1.0.6/iconify.min.js"></script>
<script type="text/javascript" src="https://cdn.jsdelivr.net/gh/pcooksey/bibtex-js/src/bibtex_js.js"></script>
<script type="text/javascript">
  function reset() {
      $("select").each(function () {
	  localStorage.setItem($(this).attr("id"),"");
	  $(this).val("");
      });
      $("#searchbar").val("");
      $("#searchbar").trigger('change');
  }
</script>

<!-- Remember to include jQuery :) -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.0.0/jquery.min.js"></script>

<!-- Academics -->
<link rel="stylesheet"
href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">

<!-- jQuery Modal -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-modal/0.9.1/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/jquery-modal/0.9.1/jquery.modal.min.css" />

<!-- additional CSS information -->
<style>
  /* Bibtex navigation bar */
  .bibtex_search_bar {
      text-align: center;
  }

  /* Bibtex item */
  .bibtexentry {
      margin-top: 0.2em;
      margin-bottom: 02em;
  }

  .url {
      background: url('https://api.iconify.design/il:url.svg') no-repeat center center / contain;
  }

  .modal { max-width: 90%; }

  /* The alert message box */
  .alert {
      padding: 20px;
      background-color: #f44336; /* Red */
      color: white;
      margin-bottom: 15px;
      width: 50%;
      margin-left: auto;
      margin-right: auto;
  }

</style>


</head>


  <body>

    <div class="container-fluid">
      <div><header class="site-header" role="banner">

	<nav class="navbar navbar-expand-sm navbar-light px-0">

		<!-- Navbar brand -->
		<a class="navbar-brand" href="/">MADHAV Lab</a>

		<!-- Navbar toggler button -->
		<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarToggler"
			aria-controls="navbarToggler" aria-expanded="false" aria-label="Toggle navigation">
			<span class="navbar-toggler-icon"></span>
		</button>

		<!-- Navbar links -->
		<div class="collapse navbar-collapse" id="navbarToggler">
			<ul class="navbar-nav mr-auto">
				<li>
					<a class="nav-link" href="/team">Team</a>
				</li>
				<li>
					<a class="nav-link" href="/publications">Publications</a>
				</li>
				<li>
					<a class="nav-link" href="/projects">Projects</a>
				</li>
				<li>
					<a class="nav-link" href="/outcomes">Outcomes</a>
				</li>
				<li>
					<a class="nav-link" href="/jobs">Jobs</a>
				</li>
				<li>
					<a class="nav-link" href="/resources">Resources</a>
				</li>
				<li>
					<a class="nav-link" href="/gallery">Gallery</a>
				</li>
			</ul>
		</div>

	</nav>

</header>
</div>

      <div class="mt-3">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <!-- Set the heights manually -->
  <style>
    h1 {
      font-size: 1.85rem;
    }
    h2 {
      font-size: 1.75rem;
    }
    h3 {
      font-size: 1.5rem;
    }
    h4 {
      font-size: 1.25rem;
    }
    h5 {
      font-size: 1rem;
    }
  </style>

  <header class="post-header">
    <h1 style="font-size:2.4rem" class="post-title p-name" itemprop="name
    headline">pyVSR - Python toolkit for Visual Speech Recognition</h1>
    <br>
    <p class="post-meta"><time class="dt-published" datetime="" itemprop="datePublished">
        
      </time><br></p>
  </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h2 id="global-information">Global information</h2>

<ul>
  <li>Repository: <a href="https://github.com/georgesterpu/pyVSR">https://github.com/georgesterpu/pyVSR</a></li>
  <li>Contact:</li>
  <li>License:</li>
  <li>Reference:</li>
</ul>

<div class="language-bibtex highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">Sterpu2017</span><span class="p">,</span>
  <span class="na">author</span>       <span class="p">=</span> <span class="s">{George Sterpu and Naomi Harte}</span><span class="p">,</span>
  <span class="na">title</span>        <span class="p">=</span> <span class="s">{Towards Lipreading Sentences with Active Appearance Models}</span><span class="p">,</span>
  <span class="na">year</span>         <span class="p">=</span> <span class="m">2017</span><span class="p">,</span>
  <span class="na">booktitle</span>    <span class="p">=</span> <span class="s">{Proc. The 14th International Conference on Auditory-Visual Speech Processing}</span><span class="p">,</span>
  <span class="na">pages</span>        <span class="p">=</span> <span class="s">{70--75}</span><span class="p">,</span>
  <span class="na">doi</span>          <span class="p">=</span> <span class="s">{10.21437/AVSP.2017-14}</span><span class="p">,</span>
  <span class="na">url</span>          <span class="p">=</span> <span class="s">{http://dx.doi.org/10.21437/AVSP.2017-14}</span>
<span class="p">}</span>
</code></pre></div></div>

<h2 id="description">Description</h2>

<p>pyVSR is a Python toolkit aimed at running Visual Speech Recognition (VSR) experiments in a traditional framework (e.g. handcrafted visual features, Hidden Markov Models for pattern recognition).</p>

<p>The main goal of pyVSR is to easily reproduce VSR experiments in order to have a baseline result on most publicly available audio-visual datasets.</p>

<h3 id="what-can-you-do-with-pyvsr">What can you do with pyVSR:</h3>

<ol>
  <li>Fetch a filtered list of files from a dataset
    <ul>
      <li>currently supported:
        <ul>
          <li>TCD-TIMIT
            <ul>
              <li>speaker-dependent protocol</li>
              <li>speaker-independent protocol</li>
              <li>single person</li>
            </ul>
          </li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Extract visual features:
    <ul>
      <li>Discrete Cosine Transform (DCT)
        <ul>
          <li>Automatic ROI extraction</li>
          <li>Configurable window size</li>
          <li>Fourth order accurate derivatives</li>
          <li>Sample rate interpolation</li>
          <li>Storage in HDF5 format</li>
        </ul>
      </li>
      <li>Active Appearance Models (AAM)
        <ul>
          <li>Do NOT require manually annotated landmarks</li>
          <li>Face, lips, and chin models supported</li>
          <li>Parameters obtainable either through fitting or projection</li>
          <li>Implementation based on Menpo</li>
        </ul>
      </li>
      <li>Point cloud of facial landmarks
        <ul>
          <li>OpenFace wrapper</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Train Hidden Markov Models (HMMs)
    <ul>
      <li>easy HTK wrapper for Python</li>
      <li>optional bigram language model</li>
      <li>multi-threaded support (both for training and decoding at full CPU Power)</li>
    </ul>
  </li>
  <li>Extend the support for additional features
    <ul>
      <li>pyVSR has a simple, modular, object-oriented architecture</li>
    </ul>
  </li>
</ol>

  </div><a class="u-url" href="/software/pyvsr" hidden></a>
</article>

      </div>

      <div>
        <div id="footer" class="site-footer mt-5">
	<div class="mt-3">
		<div class="row d-flex">

			<div class="col-sm-6">
				<p class="font-weight-bold">MADHAV Lab</p>

				<ul class="list-unstyled list-inline">
					<li class="list-inline-item">
						<a href="https://iitk.ac.in">
							<img class="img-fluid" src="/assets/images/iitk_logo.png" style="max-height: 80px;">
						</a>
					</li>

			</div>

			<div class="col-sm-3">
				<p class="font-weight-bold">Links</p>
				<ul class="list-unstyled">
					<li><a href="https://twitter.com/madhavlab" target="_blank">Twitter</a></li>
                    <li><a href="https://linkedin.com/company/madhav-lab" target="_blank">LinkedIn</a></li>
					<li><a href="https://github.com/madhavlab" target="_blank">Github</a></li>
				</ul>
			</div>

			<div class="col-sm-3">
				<p class="font-weight-bold">Contact</p>
				ACES 305D, <br>
				Electrical Engineering, <br>
				Indian Institue of Technology Kanpur, <br>
				UP, India <br>
			</div>
		</div>

		<div class="footer-copyright text-center py-3">
			Â© 2023 MADHAV Lab - Machine Analysis of Data for Human Audition and Visualization Lab
		</div>
	</div>
</div>

      </div>
    </div>

  </body>

</html>
